{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stock RNN-v3 .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lunarforest0318/Stock-Prediction/blob/master/Stock_RNN_v3_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzCetP638N38",
        "colab_type": "text"
      },
      "source": [
        "**0. Colab Set-up**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY84p-248QKJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "1e1c262a-e2e1-43ec-93fc-87d20984d4a0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNS_zScH8eEc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "428f0386-186e-4a24-e347-99a395d412aa"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/Deep Learning/RNN Stock')\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " models   ngrok-stable-linux-amd64.zip\t'Stock RNN-v2 multiclass.ipynb'\n",
            " ngrok\t  stock_data\t\t\t'Stock RNN-v3 .ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI1POhmm7js0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from collections import deque\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas_datareader as pdr\n",
        "from datetime import datetime,date\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, CuDNNLSTM, BatchNormalization\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cu1KQf67jtQ",
        "colab_type": "text"
      },
      "source": [
        "## 1. Set up Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7LmzcdH7jtS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stocks=['TQQQ','^IXIC','UCO','GLD','^TNX','^VIX']\n",
        "SEQ_LEN=40 #Last X days price to predict\n",
        "FUTURE_PERIOD_PREDICT=5 #Next X days price\n",
        "STOCK_TO_PREDICT=\"TQQQ\"\n",
        "SPLIT_RATIO=0.1\n",
        "BIG_BULL = 0.1\n",
        "SML_BULL = 0.05\n",
        "BIG_BEAR = -0.1\n",
        "SML_BEAR = -0.05\n",
        "EPOCHS=100\n",
        "BATCH_SIZE=64\n",
        "NAME=f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl3mFY6Q7jtZ",
        "colab_type": "text"
      },
      "source": [
        "## 2. Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TXRIPTqa7jta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(stocks):\n",
        "    main_df=pd.DataFrame()\n",
        "    for stock in stocks:\n",
        "        df=pdr.DataReader(stock,'yahoo',datetime(2010,1,1), date.today())\n",
        "        df.rename(columns={\"Close\":f\"{stock}_close\",\"Volume\":f\"{stock}_volume\"},inplace=True)\n",
        "        df=df[[f\"{stock}_close\",f\"{stock}_volume\"]]\n",
        "        if len(main_df)==0:\n",
        "            main_df=df\n",
        "        else:\n",
        "            main_df=main_df.join(df)\n",
        "    return main_df\n",
        "\n",
        "# #Join other macro data\n",
        "# unrate=pd.read_csv(\"stock_data/UNRATE.csv\")\n",
        "# unrate.set_index(\"Date\",inplace=True)\n",
        "# main_df=main_df.join(unrate)\n",
        "# main_df=main_df.fillna(method='ffill')\n",
        "# main_df=main_df.fillna(method='bfill')        \n",
        "        \n",
        "def classify(current,future):\n",
        "    pct_diff = (float(future)-float(current))/float(current)\n",
        "    if pct_diff >= BIG_BULL:   \n",
        "        return 4\n",
        "    elif pct_diff >= SML_BULL and pct_diff < BIG_BULL:\n",
        "        return 3\n",
        "    elif pct_diff >= BIG_BEAR and pct_diff < SML_BEAR:\n",
        "        return 1\n",
        "    elif pct_diff <= BIG_BEAR:\n",
        "        return 0\n",
        "    else:\n",
        "        return 2\n",
        "\n",
        "def preprocess_df(df):\n",
        "    df = df.drop('future',1) # we only need target column\n",
        "    df = df.drop('^TNX_volume',1) #10 yr bond - no volume\n",
        "    df = df.drop('^VIX_volume',1) #Volatility Index - no volume\n",
        "    for col in df.columns:\n",
        "        if col != \"target\":\n",
        "            df[col]=df[col].pct_change() #Percentage change between the current and a prior element.\n",
        "            df.dropna(inplace=True)\n",
        "            df[col]=preprocessing.scale(df[col].values)\n",
        "    df.dropna(inplace=True)\n",
        "    sequential_data = []\n",
        "    prev_days=deque(maxlen=SEQ_LEN)\n",
        "     \n",
        "    for i in df.values:\n",
        "        prev_days.append([n for n in i[:-1]])\n",
        "        if len(prev_days) == SEQ_LEN:\n",
        "            sequential_data.append([np.array(prev_days),i[-1]])\n",
        " \n",
        "    random.shuffle(sequential_data)#for good measure\n",
        " \n",
        "    #Balance data\n",
        "    class_bi=[]#big increase\n",
        "    class_si=[]#small increase\n",
        "    class_sc=[]#stay consistent\n",
        "    class_sd=[]#small decrease\n",
        "    class_bd=[]#big decrease\n",
        "    \n",
        "    for seq,target in sequential_data:\n",
        "        if target==4:\n",
        "            class_bi.append([seq,target])\n",
        "        elif target==3:\n",
        "            class_si.append([seq,target])\n",
        "        elif target==2:\n",
        "            class_sc.append([seq,target])\n",
        "        elif target==1:\n",
        "            class_sd.append([seq,target]) \n",
        "        elif target==0:\n",
        "            class_bd.append([seq,target])\n",
        "        \n",
        "    random.shuffle(class_bi)\n",
        "    random.shuffle(class_si)\n",
        "    random.shuffle(class_sc)\n",
        "    random.shuffle(class_sd)\n",
        "    random.shuffle(class_bd)\n",
        "            \n",
        "    lower=min(len(class_bi),len(class_si),len(class_sc),len(class_sd),len(class_bd))\n",
        "\n",
        "    class_bi=class_bi[:lower]\n",
        "    class_si=class_si[:lower]\n",
        "    class_sc=class_sc[:lower]\n",
        "    class_sd=class_sd[:lower]\n",
        "    class_bd=class_bd[:lower]\n",
        "\n",
        "    sequential_data=class_bi+class_si+class_sc+class_sd+class_bd    \n",
        "    random.shuffle(sequential_data)\n",
        "    \n",
        "    X,y=[],[]\n",
        "    \n",
        "    for seq, target in sequential_data:\n",
        "        X.append(seq)\n",
        "        y.append(target)\n",
        "        \n",
        "    return np.array(X), y\n",
        "\n",
        "def train_valid_data(main_df):\n",
        "    main_df['future']=main_df[f\"{STOCK_TO_PREDICT}_close\"].shift(-FUTURE_PERIOD_PREDICT)\n",
        "    main_df['target']=list(map(classify,main_df[f\"{STOCK_TO_PREDICT}_close\"], main_df[\"future\"]))\n",
        "    times = sorted(main_df.index.values) #Sort the index array\n",
        "    last_pct=times[-int(SPLIT_RATIO*len(main_df))]\n",
        "    validation_main_df=main_df[(main_df.index>=last_pct)]\n",
        "    train_main_df=main_df[(main_df.index<last_pct)]\n",
        "    train_x,train_y=preprocess_df(train_main_df)\n",
        "    validation_x,validation_y = preprocess_df(validation_main_df)\n",
        "    return train_x,train_y,validation_x,validation_y\n",
        "\n",
        "def data_prep_summary():\n",
        "    print(f\"train data: {len(train_x)} validation: {len(validation_x)}\")\n",
        "    print(f\"Big Bear: {train_y.count(0)} Small Bear:{train_y.count(1)} Consistent: {train_y.count(2)} Small Bull: {train_y.count(3)} Big Bull: {train_y.count(4)}\")\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ4qZ1fK7jte",
        "colab_type": "text"
      },
      "source": [
        "## 3. Build the RNN+LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLAIGRsb7jtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(train_x):\n",
        "    model=Sequential()\n",
        "    model.add(CuDNNLSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(CuDNNLSTM(128, return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(CuDNNLSTM(128))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(32, activation=\"relu\"))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(5, activation=\"softmax\"))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-61PnTP7jti",
        "colab_type": "text"
      },
      "source": [
        "## 4. Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1Gz29Fo7jtj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_main(stocks,SEQ_LEN,FUTURE_PERIOD_PREDICT,STOCK_TO_PREDICT,SPLIT_RATIO,BIG_BULL,SML_BULL,BIG_BEAR,SML_BEAR,EPOCHS,BATCH_SIZE,NAME):\n",
        "\n",
        "    main_df=prepare_data(stocks)\n",
        "    train_x,train_y,validation_x,validation_y=train_valid_data(main_df)\n",
        "    model=create_model(train_x)\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "             optimizer=keras.optimizers.Adam(lr=0.001, decay=1e-6),\n",
        "             metrics=['accuracy'])\n",
        "    tensorboard=TensorBoard(log_dir=f'logs/{NAME}')\n",
        "    filepath=\"RNNLSTM_Final_Best\"\n",
        "    checkpoint=ModelCheckpoint(\"models/{}.hdf5\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max'))\n",
        "    history=model.fit(train_x,train_y,batch_size=BATCH_SIZE,epochs=EPOCHS,validation_data=(validation_x,validation_y),callbacks=[tensorboard,checkpoint])\n",
        "\n",
        "#train_main(stocks,SEQ_LEN,FUTURE_PERIOD_PREDICT,STOCK_TO_PREDICT,SPLIT_RATIO,BIG_BULL,SML_BULL,BIG_BEAR,SML_BEAR,EPOCHS,BATCH_SIZE,NAME)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKPkUuSU9sQj",
        "colab_type": "text"
      },
      "source": [
        "Set up Tensorboard on Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_n0vpJE9W3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "# !unzip ngrok-stable-linux-amd64.zip\n",
        "tensorboard=TensorBoard(log_dir='./log', histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         write_images=True) #tensorboard on google colab\n",
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj_OeBzf7jtm",
        "colab_type": "text"
      },
      "source": [
        "## 5.Load Model and Make prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNRcuea57jtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_input(df,train_x): \n",
        "    df = df.drop('^TNX_volume',1) #10 yr bond - no volume\n",
        "    df = df.drop('^VIX_volume',1) #Volatility Index - no volume\n",
        "    df = df.drop('future',1) \n",
        "    df = df.drop('target',1)  \n",
        "    for col in df.columns:\n",
        "        if col != \"target\":\n",
        "            df[col]=df[col].pct_change() #Percentage change between the current and a prior element.\n",
        "            df[col]=preprocessing.scale(df[col].values)\n",
        "    df.dropna(inplace=True)\n",
        "    x,y = train_x.shape[1],train_x.shape[2]\n",
        "    df = np.array(df)\n",
        "    df = df[-x:,:].reshape(1,x,y)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMUK0EM17jtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_prediction(stocks):\n",
        "    main_df=prepare_data(stocks)\n",
        "    train_x,train_y,validation_x,validation_y=train_valid_data(main_df)\n",
        "    model=create_model(train_x)\n",
        "    model.load_weights(\"models/RNNLSTM_Final_Best.hdf5\")\n",
        "    \n",
        "    input=main_df.iloc[-int(1.5*SEQ_LEN):,:]\n",
        "    input=process_input(input,train_x)\n",
        "    output = model.predict_classes(input)\n",
        "    output_prob = model.predict_proba(input)\n",
        "    \n",
        "    if output==4:\n",
        "        pred=\"significantly increase\"\n",
        "    elif output==3:\n",
        "        pred=\"increase\"\n",
        "    elif output==1:\n",
        "        pred=\"decrease\"\n",
        "    elif output==0:\n",
        "        pred=\"significantly decrease\"\n",
        "    else:\n",
        "        pred=\"stay consistent\"\n",
        "    print(f\"The stock price for {STOCK_TO_PREDICT} in the next {FUTURE_PERIOD_PREDICT} days will {pred}\")\n",
        "    print(\"Details:\")\n",
        "    print(\"Big Bull:\", f\"{output_prob[0][4]:.02%}\")\n",
        "    print(\"Small Bull:\", f\"{output_prob[0][3]:.02%}\")\n",
        "    print(\"Consistent:\", f\"{output_prob[0][2]:.02%}\")\n",
        "    print(\"Small Bear:\", f\"{output_prob[0][1]:.02%}\")\n",
        "    print(\"Big Bear:\", f\"{output_prob[0][0]:.02%}\")\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k_Mgje-7jtx",
        "colab_type": "code",
        "outputId": "12a7f00b-4dda-408d-9860-c8a8b845c0a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "make_prediction(stocks)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "The stock price for TQQQ in the next 5 days will increase\n",
            "Details:\n",
            "Big Bull: 11.10%\n",
            "Small Bull: 87.74%\n",
            "Consistent: 1.10%\n",
            "Small Bear: 0.07%\n",
            "Big Bear: 0.01%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBcm69dc7jt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnHOWC4r8cQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}